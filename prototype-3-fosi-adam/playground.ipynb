{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "import torch\n",
    "import evaluate\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Tuple\n",
    "\n",
    "class CustomDataLoader:\n",
    "    def __init__(self, dataset_from: str = 'glue', model_name: str = 'bert-based-uncased', dataset_task: str = 'sst2', seed_num: int = 42, range_to_select: int = 500, batch_size: int = 8):\n",
    "        \"\"\"\n",
    "        Custom DataLoader class for preparing and loading datasets.\n",
    "\n",
    "        Args:\n",
    "            dataset_from (str, optional): Name of the dataset. Defaults to 'glue'.\n",
    "            model_name (str, optional): Name of the pretrained model. Defaults to 'bert-based-uncased'.\n",
    "            dataset_task (str, optional): Name of the dataset task. Defaults to 'sst2'.\n",
    "            seed_num (int, optional): Random seed number. Defaults to 42.\n",
    "            range_to_select (int, optional): Range of data to select. Defaults to 500.\n",
    "            batch_size (int, optional): Batch size. Defaults to 8.\n",
    "        \"\"\"\n",
    "        self.dataset_from = dataset_from\n",
    "        self.model_name = model_name\n",
    "        self.dataset_task = dataset_task\n",
    "        self.seed_num = seed_num\n",
    "        self.range_to_select = range_to_select\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.GLUE_TASKS = [\"cola\", \"mnli\", \"mnli-mm\", \"mrpc\", \"qnli\", \"qqp\", \"rte\", \"sst2\", \"stsb\", \"wnli\"]\n",
    "        self.task_to_keys = {\n",
    "            \"cola\": (\"sentence\", None),\n",
    "            \"mnli\": (\"premise\", \"hypothesis\"),\n",
    "            \"mnli-mm\": (\"premise\", \"hypothesis\"),\n",
    "            \"mrpc\": (\"sentence1\", \"sentence2\"),\n",
    "            \"qnli\": (\"question\", \"sentence\"),\n",
    "            \"qqp\": (\"question1\", \"question2\"),\n",
    "            \"rte\": (\"sentence1\", \"sentence2\"),\n",
    "            \"sst2\": (\"sentence\", None),\n",
    "            \"stsb\": (\"sentence1\", \"sentence2\"),\n",
    "            \"wnli\": (\"sentence1\", \"sentence2\"),\n",
    "        }\n",
    "        self.sentence1_key, self.sentence2_key = self.task_to_keys[self.dataset_task]\n",
    "\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        self.data_collator = DataCollatorWithPadding(tokenizer=self.tokenizer, padding=True)\n",
    "        self.metric = evaluate.load(self.dataset_from, self.dataset_task)\n",
    "\n",
    "    def get_custom_data_loaders(self) -> Tuple[DataLoader, DataLoader, DataLoader, evaluate.Metric]:\n",
    "        \"\"\"\n",
    "        Get custom data loaders for training and testing.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[DataLoader, DataLoader, DataLoader, evaluate.Metric]: Tuple containing train loader, val_loader, test loader, and metric.\n",
    "        \"\"\"\n",
    "        dataset = load_dataset(self.dataset_from, self.dataset_task).map(self._prepare_dataset, batched=True)\n",
    "        dataset = concatenate_datasets([dataset[\"train\"], dataset[\"validation\"]]).train_test_split(test_size=0.1666666666666, seed=self.seed_num, stratify_by_column='label')\n",
    "\n",
    "        # train_dataset = dataset['train'].select(range(self.range_to_select)).remove_columns(['sentence', 'idx']).rename_column('label', 'labels')\n",
    "        # test_dataset = dataset['test'].select(range(self.range_to_select)).remove_columns(['sentence', 'idx']).rename_column('label', 'labels')\n",
    "\n",
    "        train_dataset = dataset['train'].select(range(self.range_to_select)).remove_columns(['idx'] + [col for col in dataset[\"train\"].column_names if col in self.task_to_keys[self.dataset_task]]).rename_column('label', 'labels')\n",
    "        val_dataset = dataset['train'].select(range(self.range_to_select, 2*self.range_to_select)).remove_columns(['idx'] + [col for col in dataset[\"test\"].column_names if col in self.task_to_keys[self.dataset_task]]).rename_column('label', 'labels')\n",
    "        test_dataset = dataset['test'].select(range(self.range_to_select)).remove_columns(['idx'] + [col for col in dataset[\"test\"].column_names if col in self.task_to_keys[self.dataset_task]]).rename_column('label', 'labels')\n",
    "\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True, collate_fn=self.data_collator)\n",
    "        val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=self.batch_size, shuffle=True, collate_fn=self.data_collator)\n",
    "        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=self.batch_size, shuffle=True, collate_fn=self.data_collator)\n",
    "        return train_loader, val_loader, test_loader, self.metric\n",
    "\n",
    "    def _prepare_dataset(self, examples) -> dict:\n",
    "        \"\"\"\n",
    "        Prepare dataset for training and testing.\n",
    "\n",
    "        Args:\n",
    "            examples: Input examples.\n",
    "\n",
    "        Returns:\n",
    "            dict: Tokenized examples.\n",
    "        \"\"\"\n",
    "        if self.sentence2_key is None:\n",
    "            return self.tokenizer(examples[self.sentence1_key], truncation=True)\n",
    "        return self.tokenizer(examples[self.sentence1_key], examples[self.sentence2_key], truncation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, mean_absolute_error, roc_auc_score, matthews_corrcoef\n",
    "from torch.utils.tensorboard import SummaryWriter  # Import SummaryWriter for TensorBoard logging\n",
    "\n",
    "class Logger:\n",
    "    def __init__(self):\n",
    "        self.train_losses = []\n",
    "        self.train_f1_scores = []\n",
    "        self.train_accuracies = []\n",
    "        self.train_precisions = []\n",
    "        self.train_recalls = []\n",
    "        self.train_maes = []\n",
    "        self.train_auc_roc = []\n",
    "        self.train_mcc = []  # Added list for MCC\n",
    "        self.validation_losses = []  # Store validation losses\n",
    "        self.validation_f1_scores = []  # Store validation F1 scores\n",
    "        self.writer = SummaryWriter()  # Initialize SummaryWriter for TensorBoard logging\n",
    "\n",
    "    def log_train_epoch(self, epoch, loss, preds, labels):\n",
    "        self.train_losses.append(loss)\n",
    "\n",
    "        train_f1 = f1_score(labels, preds)\n",
    "        self.train_f1_scores.append(train_f1)\n",
    "\n",
    "        train_accuracy = accuracy_score(labels, preds)\n",
    "        self.train_accuracies.append(train_accuracy)\n",
    "\n",
    "        train_precision = precision_score(labels, preds)\n",
    "        self.train_precisions.append(train_precision)\n",
    "\n",
    "        train_recall = recall_score(labels, preds)\n",
    "        self.train_recalls.append(train_recall)\n",
    "\n",
    "        train_mae = mean_absolute_error(labels, preds)\n",
    "        self.train_maes.append(train_mae)\n",
    "\n",
    "        train_auc_roc = roc_auc_score(labels, preds)\n",
    "        self.train_auc_roc.append(train_auc_roc)\n",
    "\n",
    "        train_mcc = matthews_corrcoef(labels, preds)  # Calculate MCC\n",
    "        self.train_mcc.append(train_mcc)  # Append MCC to the list\n",
    "\n",
    "        # Log metrics to TensorBoard\n",
    "        self.writer.add_scalar('Loss/train', loss, epoch)\n",
    "        self.writer.add_scalar('F1 Score/train', train_f1, epoch)\n",
    "        self.writer.add_scalar('Accuracy/train', train_accuracy, epoch)\n",
    "        self.writer.add_scalar('Precision/train', train_precision, epoch)\n",
    "        self.writer.add_scalar('Recall/train', train_recall, epoch)\n",
    "        self.writer.add_scalar('MAE/train', train_mae, epoch)\n",
    "        self.writer.add_scalar('AUC ROC/train', train_auc_roc, epoch)\n",
    "        self.writer.add_scalar('MCC/train', train_mcc, epoch)  # Log MCC to TensorBoard\n",
    "\n",
    "        print(f\"Epoch {epoch}: Loss: {loss}, F1 Score: {train_f1}, Accuracy: {train_accuracy}, Precision: {train_precision}, Recall: {train_recall}, MAE: {train_mae}, AUC ROC: {train_auc_roc}, MCC: {train_mcc}\")\n",
    "\n",
    "    def log_validation_epoch(self, epoch, loss, preds, labels):\n",
    "        self.validation_losses.append(loss)\n",
    "\n",
    "        validation_f1 = f1_score(labels, preds)\n",
    "        self.validation_f1_scores.append(validation_f1)\n",
    "\n",
    "        validation_accuracy = accuracy_score(labels, preds)\n",
    "        validation_precision = precision_score(labels, preds)\n",
    "        validation_recall = recall_score(labels, preds)\n",
    "        validation_mae = mean_absolute_error(labels, preds)\n",
    "        validation_auc_roc = roc_auc_score(labels, preds)\n",
    "        validation_mcc = matthews_corrcoef(labels, preds)\n",
    "\n",
    "        # Log metrics to TensorBoard\n",
    "        self.writer.add_scalar('Loss/validation', loss, epoch)\n",
    "        self.writer.add_scalar('F1 Score/validation', validation_f1, epoch)\n",
    "        self.writer.add_scalar('Accuracy/validation', validation_accuracy, epoch)\n",
    "        self.writer.add_scalar('Precision/validation', validation_precision, epoch)\n",
    "        self.writer.add_scalar('Recall/validation', validation_recall, epoch)\n",
    "        self.writer.add_scalar('MAE/validation', validation_mae, epoch)\n",
    "        self.writer.add_scalar('AUC ROC/validation', validation_auc_roc, epoch)\n",
    "        self.writer.add_scalar('MCC/validation', validation_mcc, epoch)\n",
    "\n",
    "        print(f\"Validation at epoch {epoch}: Loss: {loss}, F1 Score: {validation_f1}, Accuracy: {validation_accuracy}, Precision: {validation_precision}, Recall: {validation_recall}, MAE: {validation_mae}, AUC ROC: {validation_auc_roc}, MCC: {validation_mcc}\")\n",
    "\n",
    "    def log_test_metrics(self, test_loss, test_preds, test_labels):\n",
    "        test_f1 = f1_score(test_labels, test_preds)\n",
    "        test_accuracy = accuracy_score(test_labels, test_preds)\n",
    "        test_precision = precision_score(test_labels, test_preds)\n",
    "        test_recall = recall_score(test_labels, test_preds)\n",
    "        test_mae = mean_absolute_error(test_labels, test_preds)\n",
    "        test_auc_roc = roc_auc_score(test_labels, test_preds)\n",
    "        test_mcc = matthews_corrcoef(test_labels, test_preds)\n",
    "\n",
    "        # Log metrics to TensorBoard\n",
    "        self.writer.add_scalar('Loss/test', test_loss)\n",
    "        self.writer.add_scalar('F1 Score/test', test_f1)\n",
    "        self.writer.add_scalar('Accuracy/test', test_accuracy)\n",
    "        self.writer.add_scalar('Precision/test', test_precision)\n",
    "        self.writer.add_scalar('Recall/test', test_recall)\n",
    "        self.writer.add_scalar('MAE/test', test_mae)\n",
    "        self.writer.add_scalar('AUC ROC/test', test_auc_roc)\n",
    "        self.writer.add_scalar('MCC/test', test_mcc)\n",
    "\n",
    "        print(f\"Test Metrics: Loss: {test_loss}, F1 Score: {test_f1}, Accuracy: {test_accuracy}, Precision: {test_precision}, Recall: {test_recall}, MAE: {test_mae}, AUC ROC: {test_auc_roc}, MCC: {test_mcc}\")\n",
    "\n",
    "    def plot_metrics(self):\n",
    "        epochs = range(1, len(self.train_losses) + 1)\n",
    "\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.subplot(1, 5, 1)\n",
    "        plt.plot(epochs, self.train_losses, label='Training Loss')\n",
    "        plt.plot(epochs, self.validation_losses, label='Validation Loss')  # Add validation loss plot\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training and Validation Loss')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(1, 5, 2)\n",
    "        plt.plot(epochs, self.train_f1_scores, label='Training F1 Score')\n",
    "        plt.plot(epochs, self.validation_f1_scores, label='Validation F1 Score')  # Add validation F1 score plot\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('F1 Score')\n",
    "        plt.title('Training and Validation F1 Score')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def close(self):\n",
    "        self.writer.close()  # Close the SummaryWriter when logging is complete\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-08 19:59:42,667] torch.distributed.elastic.multiprocessing.redirects: [WARNING] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from fosi import fosi_adam_torch\n",
    "import copy\n",
    "import torchopt\n",
    "import functorch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import Tensor\n",
    "from typing import Tuple\n",
    "from logger import Logger  # Import the modified Logger class for logging\n",
    "\n",
    "class CustomTrainer:\n",
    "    def __init__(self, original_model: torch.nn.Module, train_loader: DataLoader, val_loader: DataLoader = None,epochs: int = 1):\n",
    "        self.original_model = original_model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.epochs = epochs\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.logger = Logger()  # Initialize the modified Logger class for logging\n",
    "\n",
    "    def train(self) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        self.original_model.train()\n",
    "        self.original_model.to(self.device)\n",
    "\n",
    "        base_optimizer = torchopt.adam(lr=0.01)\n",
    "        data = next(iter(self.train_loader))\n",
    "        optimizer = fosi_adam_torch(base_optimizer, self.loss_fn, data, num_iters_to_approx_eigs=500, alpha=0.01)\n",
    "        self.functional_model, self.params, self.buffers = self.make_functional_with_buffers(self.original_model)\n",
    "        # self.functional_model, self.params, self.buffers = torch.func.functional_call(self.original_model, dict(self.original_model.named_parameters()))\n",
    "        \n",
    "        opt_state = optimizer.init(self.params)   \n",
    "\n",
    "        self.original_model.train()\n",
    "        # self.functional_model.train()\n",
    "        for epoch in range(self.epochs):\n",
    "            epoch_loss = 0.0  # Reset epoch loss for each epoch\n",
    "            epoch_preds = []\n",
    "            epoch_labels = []\n",
    "            progress_bar = tqdm(enumerate(self.train_loader, 1), total=len(self.train_loader))\n",
    "            for i, data in progress_bar:\n",
    "                self.original_model.train()\n",
    "                progress_bar.set_description(f'Epoch {epoch+1}/{self.epochs}, Step {i}/{len(self.train_loader)}')\n",
    "\n",
    "                input_ids = data['input_ids'].squeeze().to(self.device)\n",
    "                attention_mask = data['attention_mask'].squeeze().to(self.device)\n",
    "                labels = data['labels'].squeeze().to(self.device)\n",
    "\n",
    "                # Calculate loss, with params from previous iteration\n",
    "                loss, _ = self.loss_fn(self.params, self.buffers, input_ids, attention_mask, labels)\n",
    "                epoch_loss += loss.item()  # Accumulate loss for each batch\n",
    "\n",
    "                # Calculate gradients based on loss value\n",
    "                grads = torch.autograd.grad(loss, self.params)\n",
    "                updates, opt_state = optimizer.update(grads, opt_state, self.params)\n",
    "                self.params = torchopt.apply_updates(self.params, updates, inplace=True)\n",
    "\n",
    "                # Bar responsible\n",
    "                progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "                # Get predictions with updated params\n",
    "                self.functional_model, self.params, self.buffers = self.make_functional_with_buffers(mod=self.original_model, new_params_values=self.params, new_buffers_values=self.buffers)\n",
    "                preds = self.functional_model(input_ids=input_ids, attention_mask = attention_mask)\n",
    "                predictions = torch.round(preds).to(torch.float32)\n",
    "\n",
    "                epoch_preds.extend(predictions.detach().cpu().numpy())\n",
    "                epoch_labels.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "            epoch_loss /= self.train_loader.__len__()  # Calculate average loss per epoch\n",
    "            self.logger.log_train_epoch(epoch + 1, epoch_loss, epoch_preds, epoch_labels)  # Log epoch metrics using the modified Logger class\n",
    "\n",
    "            # Perform validation check here and log validation metrics\n",
    "            if self.val_loader != None:\n",
    "                validation_loss, validation_preds, validation_labels = self.validate()  # Implement validate() method\n",
    "                self.logger.log_validation_epoch(epoch + 1, validation_loss, validation_preds, validation_labels)\n",
    "\n",
    "        self.logger.close()  # Close the SummaryWriter when logging is complete\n",
    "\n",
    "        return self.functional_model, self.params, self.buffers\n",
    "\n",
    "    # def loss_fn(self, functional_model: callable, params: Tuple[Tensor], buffers: Tuple[Tensor], input_ids: Tensor, attention_mask: Tensor, labels: Tensor) -> Tensor:\n",
    "    #     preds = functional_model(params=params, buffers=buffers, input_ids=input_ids, attention_mask=attention_mask)\n",
    "    #     loss = torch.nn.functional.binary_cross_entropy(preds.squeeze().to(torch.float32), labels.squeeze().to(torch.float32))\n",
    "    #     return loss\n",
    "\n",
    "    def loss_fn(self, params: Tuple[Tensor], buffers: Tuple[Tensor], input_ids: Tensor, attention_mask: Tensor, labels: Tensor) -> Tensor:\n",
    "        fmodel, _, __ = self.make_functional_with_buffers(mod=self.original_model, new_params_values=params, new_buffers_values=buffers)\n",
    "        preds = fmodel(input_ids=input_ids, attention_mask = attention_mask)\n",
    "        loss = torch.nn.functional.binary_cross_entropy(preds.squeeze().to(torch.float32), labels.squeeze().to(torch.float32))\n",
    "        return loss, preds\n",
    "\n",
    "    def validate(self) -> Tuple[float, list, list]:\n",
    "        # Implement validation check here, this will run per epoch, it is NOT a test functionality.\n",
    "        # This function should return validation loss, predictions, and labels for validation set\n",
    "        # self.original_model.eval()  # Set model to evaluation mode\n",
    "        val_loss = 0.0\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "        progress_bar = tqdm(enumerate(self.val_loader, 0), total=len(self.val_loader))\n",
    "        with torch.no_grad():\n",
    "            for i, data in progress_bar:\n",
    "                progress_bar.set_postfix(val_loss=val_loss)\n",
    "\n",
    "                input_ids = data['input_ids'].squeeze().to(self.device)\n",
    "                attention_mask = data['attention_mask'].squeeze().to(self.device)\n",
    "                labels = data['labels'].squeeze().to(self.device)\n",
    "\n",
    "                # fmodel, _, __ = self.make_functional_with_buffers(mod=self.original_model, new_params_values=self.params, new_buffers_values=self.buffers)\n",
    "                # preds = fmodel(input_ids=input_ids, attention_mask = attention_mask)\n",
    "                loss, preds = self.loss_fn(self.params, self.buffers, input_ids, attention_mask, labels)\n",
    "                val_loss += loss.item()  # Accumulate validation loss\n",
    "\n",
    "                predictions = torch.round(preds).to(torch.float32)\n",
    "                val_preds.extend(predictions.detach().cpu().numpy())\n",
    "                val_labels.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "        val_loss /= self.val_loader.__len__()  # Calculate average validation loss\n",
    "        return val_loss, val_preds, val_labels\n",
    "\n",
    "    def test(self, test_loader: DataLoader):\n",
    "        # Implement test method here\n",
    "        # This function should log test metrics using the modified Logger class\n",
    "        self.test_loader = test_loader    \n",
    "        self.original_model.eval()  # Set model to evaluation mode\n",
    "        test_loss = 0.0\n",
    "        test_preds = []\n",
    "        test_labels = []\n",
    "        progress_bar = tqdm(enumerate(self.test_loader, 0), total=len(self.test_loader))\n",
    "        with torch.no_grad():\n",
    "            for i, data in progress_bar:\n",
    "                progress_bar.set_description(f'Testing {i}/{len(self.test_loader)}')\n",
    "\n",
    "                input_ids = data['input_ids'].squeeze().to(self.device)\n",
    "                attention_mask = data['attention_mask'].squeeze().to(self.device)\n",
    "                labels = data['labels'].squeeze().to(self.device)\n",
    "\n",
    "                # fmodel, _, __ = self.make_functional_with_buffers(mod=self.original_model, new_params_values=self.params, new_buffers_values=self.buffers)\n",
    "                # preds = fmodel(input_ids=input_ids, attention_mask = attention_mask)\n",
    "                loss, preds = self.loss_fn(self.params, self.buffers, input_ids, attention_mask, labels)\n",
    "                test_loss += loss.item()  # Accumulate test loss\n",
    "\n",
    "                predictions = torch.round(preds).to(torch.float32)\n",
    "                test_preds.extend(predictions.detach().cpu().numpy())\n",
    "                test_labels.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "        test_loss /= len(self.test_loader)  # Calculate average test loss\n",
    "        # self.original_model.train() # Make train mode again for the next loop, if there is any\n",
    "\n",
    "        # Log test metrics\n",
    "        self.logger.log_test_metrics(test_loss, test_preds, test_labels)\n",
    "\n",
    "        return self.functional_model, self.params, self.buffers\n",
    "\n",
    "    # def make_functional(self, mod, new_params_values=None, disable_autograd_tracking=False):\n",
    "    #     params_dict = dict(mod.named_parameters())\n",
    "    #     params_names = params_dict.keys()\n",
    "    #     params_values = tuple(params_dict.values())\n",
    "        \n",
    "    #     stateless_mod = copy.deepcopy(mod)\n",
    "    #     stateless_mod.to('meta')\n",
    "\n",
    "    #     # This remains Unchanged and not used in the code\n",
    "    #     def fmodel(new_params_values=new_params_values, *args, **kwargs):\n",
    "    #         if new_params_values is None:\n",
    "    #             # This is the first call to the functional model\n",
    "    #             new_params_values = params_values\n",
    "    #         new_params_dict = {name: value for name, value in zip(params_names, new_params_values)}\n",
    "    #         return torch.func.functional_call(stateless_mod, new_params_dict, args, kwargs)\n",
    "    \n",
    "    #     if disable_autograd_tracking:\n",
    "    #         params_values = torch.utils._pytree.tree_map(torch.Tensor.detach, params_values)\n",
    "    #     return fmodel, params_values\n",
    "\n",
    "    def make_functional_with_buffers(self, mod, new_params_values=None, new_buffers_values=None, disable_autograd_tracking=False):\n",
    "\n",
    "        \"\"\"\n",
    "        Given a module, return a functional version of the module that can be called with\n",
    "        the parameters and buffers as arguments. This is useful for optimization libraries\n",
    "        that require a functional interface to the model.\n",
    "\n",
    "        Args:\n",
    "            mod: A PyTorch module.\n",
    "            disable_autograd_tracking: If True, the parameters will be detached from the computation graph.\n",
    "\n",
    "        Returns:\n",
    "            A tuple (fmodel, params, buffers), where:\n",
    "            - fmodel is a functional version of the module.\n",
    "            - params is a tuple of the parameters of the module.\n",
    "            - buffers is a tuple of the buffers of the module.\n",
    "        \n",
    "        This was taken from the official PyTorch library.\n",
    "        Repo Link: https://gist.github.com/zou3519/7769506acc899d83ef1464e28f22e6cf\n",
    "        Original Docs: https://pytorch.org/docs/stable/func.migrating.html#function-transforms\n",
    "        \"\"\"\n",
    "        params_dict = dict(mod.named_parameters())\n",
    "        params_names = params_dict.keys()\n",
    "        params_values = tuple(params_dict.values())\n",
    "\n",
    "        buffers_dict = dict(mod.named_buffers())\n",
    "        buffers_names = buffers_dict.keys()\n",
    "        buffers_values = tuple(buffers_dict.values())\n",
    "        \n",
    "        stateless_mod = copy.deepcopy(mod)\n",
    "        stateless_mod.to('meta')\n",
    "\n",
    "        # def fmodel(new_params_values=new_buffers_values, new_buffers_values=new_buffers_values, *args, **kwargs):\n",
    "        #     if new_params_values is None:\n",
    "        #         # This is the first call to the functional model\n",
    "        #         new_params_values = params_values\n",
    "        #     if new_buffers_values is None:\n",
    "        #         # This is the first call to the functional model\n",
    "        #         new_buffers_values = buffers_values\n",
    "        #     new_params_dict = {name: value for name, value in zip(params_names, new_params_values)}\n",
    "        #     new_buffers_dict = {name: value for name, value in zip(buffers_names, new_buffers_values)}\n",
    "        #     return torch.func.functional_call(stateless_mod, (new_params_dict, new_buffers_dict), args, kwargs)\n",
    "        \n",
    "        # Inner function\n",
    "        def fmodel(new_params_values=new_params_values, new_buffers_values=new_buffers_values, *args, **kwargs):\n",
    "            if new_params_values is None:\n",
    "                # This is the first call to the functional model\n",
    "                new_params_values = params_values\n",
    "            if new_buffers_values is None:\n",
    "                # This is the first call to the functional model\n",
    "                new_buffers_values = buffers_values\n",
    "            new_params_dict = {name: value for name, value in zip(params_names, new_params_values)}\n",
    "            new_buffers_dict = {name: value for name, value in zip(buffers_names, new_buffers_values)}\n",
    "            return torch.func.functional_call(stateless_mod, (new_params_dict, new_buffers_dict), args=args, kwargs=kwargs)\n",
    "\n",
    "        if disable_autograd_tracking:\n",
    "            params_values = torch.utils._pytree.tree_map(torch.Tensor.detach, params_values)\n",
    "\n",
    "        # del stateless_mod\n",
    "        return fmodel, params_values, buffers_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned ESE function. Lanczos order (m) is 20 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Step 1/13:   0%|          | 0/13 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "CustomTrainer.loss_fn() takes 6 positional arguments but 7 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 47\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m     43\u001b[0m trainer \u001b[38;5;241m=\u001b[39m CustomTrainer(original_model, \n\u001b[1;32m     44\u001b[0m     train_loader, \n\u001b[1;32m     45\u001b[0m     val_loader, \n\u001b[1;32m     46\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mepochs)\n\u001b[0;32m---> 47\u001b[0m functional_model, params, buffers \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Get functional model, params, and buffers\u001b[39;00m\n\u001b[1;32m     49\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtest(test_loader\u001b[38;5;241m=\u001b[39mtest_loader)\n",
      "File \u001b[0;32m~/Documents/nlp-optimizers/nlp-optimizers/prototype-3-fosi-adam/training.py:49\u001b[0m, in \u001b[0;36mCustomTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     46\u001b[0m labels \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Calculate loss, with params from previous iteration\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m loss, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuffers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()  \u001b[38;5;66;03m# Accumulate loss for each batch\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Calculate gradients based on loss value\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: CustomTrainer.loss_fn() takes 6 positional arguments but 7 were given"
     ]
    }
   ],
   "source": [
    "from model import BertClassifier\n",
    "from dataset import CustomDataLoader\n",
    "from training import CustomTrainer\n",
    "from evaluation import CustomEvaluator\n",
    "from utils import set_seed\n",
    "\n",
    "# Prompt user for dataset choice\n",
    "dataset_from = input(\"Enter the dataset you want to use (e.g., 'glue'): \") or 'glue'\n",
    "\n",
    "# Prompt user for model name\n",
    "model_name = input(\"Enter the model name (e.g., 'bert-base-uncased'): \") or 'bert-base-uncased'\n",
    "\n",
    "# Prompt user for dataset task\n",
    "dataset_task = input(\"Enter the dataset task (e.g., 'sst2'): \") or 'sst2'\n",
    "\n",
    "# Prompt user for seed number\n",
    "seed_num = int(input(\"Enter the seed number (default is 42): \") or '42')\n",
    "\n",
    "# Prompt user for number of epochs\n",
    "epochs = int(input(\"Enter the number of epochs (default is 2): \") or '2')\n",
    "\n",
    "# Set seed for reproducibility\n",
    "set_seed(seed_num)\n",
    "\n",
    "# Load model\n",
    "original_model = BertClassifier(\n",
    "    model_name=model_name,\n",
    "    num_classes=3 if dataset_task.startswith(\"mnli\") else 1 if dataset_task == \"stsb\" else 2\n",
    ")\n",
    "\n",
    "# Prepare dataset\n",
    "custom_dataloader = CustomDataLoader(\n",
    "    dataset_from=dataset_from,\n",
    "    model_name=model_name,\n",
    "    dataset_task=dataset_task,\n",
    "    seed_num=seed_num,\n",
    "    range_to_select=100,  # Default value for now, you can prompt the user for this too if needed\n",
    "    batch_size=8  # Default value for now, you can prompt the user for this too if needed\n",
    ")\n",
    "train_loader, val_loader, test_loader, metric = custom_dataloader.get_custom_data_loaders()\n",
    "\n",
    "# Train model\n",
    "trainer = CustomTrainer(original_model, \n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    epochs=epochs)\n",
    "functional_model, params, buffers = trainer.train()  # Get functional model, params, and buffers\n",
    "\n",
    "trainer.test(test_loader=test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pavlosEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
